{
 "metadata": {
  "name": "",
  "signature": "sha256:828a2be9145ab4af8a147ab9a52f3520ea0f6e4a617c3e0c0483a5bc5bb23fe0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from fuzzywuzzy import fuzz\n",
      "from fuzzywuzzy import process\n",
      "\n",
      "#match flags: z: zip, n: street number, d: direction, s: street name, t: street type\n",
      "\n",
      "class addr_match():\n",
      "    def __init__(self, match_path, match_fields={'address':'SITUSADD', 'zip': 'SZIP', 'id': 'APN', 'lat':'lat', 'lon':'lon'}, **kwargs):\n",
      "            \n",
      "            self.match_fields = match_fields\n",
      "            df = pd.read_csv(match_path, **kwargs)\n",
      "            df_sub = df[match_fields.values()]\n",
      "            self.match_df = df_sub.dropna(subset=[self.match_fields['address'], self.match_fields['id']])\n",
      "            self.matched = pd.DataFrame(columns=match_fields.values())\n",
      "#            self.unmatched = pd.DataFrame(columns=match_fields.values())\n",
      "\n",
      "    def abbrv_init(self, abbrv_path, **kwargs):\n",
      "            abbrv = pd.read_csv(abbrv_path, **kwargs)\n",
      "            abbrv[1] = abbrv[1].str.replace('[^A-Z]', '')\n",
      "            abbrv[0] = abbrv[0].str.replace(' ', '')\n",
      "            abbrv.loc[abbrv[0] == 'WAY', 1] = 'WY'\n",
      "            abbrv_li = list(abbrv[1])\n",
      "            additions = ['HAVEN', 'GLEN', 'GLENN', 'WAY', 'TR', 'PT', 'POINT', 'HW', 'LP', 'PW', 'PZ', 'COURT', 'GAP', 'HOLLOW', 'STR', 'CROSSING', 'PLACE', 'PKY', 'ALLEY', 'AVENUE', 'BOULEVARD', 'DRIVE', 'ROAD', 'FREEWAY', 'HIGHWAY', 'LANE', 'PARKWAY', 'WALK', 'CENTER', 'CIRCLE', 'STREET'] \n",
      "            abbrv_li.extend(additions)\n",
      "            abbrv_str = '| '.join(abbrv_li)\n",
      "            self.abbrv = abbrv\n",
      "            self.abbrv_str = abbrv_str\n",
      "\n",
      "    def prep_match(self):\n",
      "\n",
      "\t    type1 = self.match_df[self.match_fields['address']].str.extract(\"(\\d*) *(N\\.?|S\\.?|E\\.?|W\\.?) +([A-Z,0-9, ,-,',\\.]*) *( %s)$\" % (self.abbrv_str))\n",
      "\n",
      "\t    nontype1 = self.match_df.loc[~self.match_df[self.match_fields['address']].str.contains(\"(\\d*) *(N\\.?|S\\.?|E\\.?|W\\.?) +([A-Z,0-9, ,-,',\\.]*) *( %s)$\" % (self.abbrv_str))]\n",
      "\n",
      "\t    type2 = nontype1[self.match_fields['address']].loc[nontype1[self.match_fields['address']].str.contains(\" [N\\.?|W\\.?|S\\.?|E\\.?] \")].str.extract(\"(\\d*) *(N\\.?|S\\.?|E\\.?|W\\.?) +([A-Z,0-9, ,-,',\\.]*)$\")\n",
      "\n",
      "\t    type3 = nontype1[self.match_fields['address']].loc[~nontype1[self.match_fields['address']].str.contains(\" [N\\.?|W\\.?|S\\.?|E\\.?] \")].str.extract(\"(\\d*) *([A-Z,0-9, ,-,',\\.]*)( %s)$\" % (self.abbrv_str))\n",
      "\n",
      "\t    type1_names = pd.DataFrame(type1.dropna()[[0,1,2,3]]).rename(columns={0:'SNUM', 1:'DIR', 2:'STREET', 3:'STYPE'})\n",
      "\t    type2_names = pd.DataFrame(type2.dropna()[[0,2]]).rename(columns={0:'SNUM',1:'DIR', 2:'STREET'})\n",
      "\t\t\n",
      "\t    type3_names = pd.DataFrame(type3.dropna()[[0,1]]).rename(columns={0:'SNUM', 1:'STREET', 2:'STYPE'})\n",
      "\t\t\n",
      "\n",
      "#### CREATE STREET NAME SERIES\n",
      "\t    street_loc = pd.concat([type1_names, type2_names, type3_names], axis=0)\n",
      "\t    street_names = street_loc['STREET']\n",
      "\t    street_names = street_names.drop(street_names[street_names.str.len() == 1].index)\n",
      "\t    self.street_names = street_names.drop(street_names[street_names.isin(['RD', 'PL', 'LP', 'DR', 'HWY', 'OLD', 'VIS'])].index)\n",
      "\n",
      "#### CREATE SORTED STREET NAME STRING\n",
      "\n",
      "\t    streetsort = pd.DataFrame(street_names.unique())\n",
      "\t    streetsort['len'] = streetsort[0].str.len()\n",
      "\t    self.streetsort_str = '|'.join(streetsort.sort('len', ascending=False)[0].values)\n",
      "\n",
      "\t    self.match_df = pd.concat([self.match_df, street_loc], axis=1)\n",
      "\t    self.match_df['STYPE'] = self.match_df['STYPE'].str.replace(' ', '')\n",
      "\n",
      "\t    self.match_wf = self.match_df.drop_duplicates(subset=[self.match_fields['address']])[[self.match_fields['address'], self.match_fields['id'], 'SNUM', 'DIR', 'STREET', 'STYPE', self.match_fields['zip'], 'lat', 'lon']]\n",
      "\n",
      "\t    self.match_wf[self.match_fields['address']] = self.match_wf[self.match_fields['address']].str.replace('.', '').str.replace(',', '')\n",
      "\n",
      "\t    self.match_wf['STYPE'] = self.match_wf['STYPE'].map(pd.Series(self.abbrv.set_index(0)[1])).fillna(self.match_wf['STYPE'])\n",
      "\n",
      "\n",
      "    def target_init(self, target_path, match_fields={'address':'DRESADDRES', 'zip':'DRESZIP', 'id':'FID_1'}, **kwargs):\n",
      "\n",
      "\t    self.match_fields['t_id'] = match_fields['id']\n",
      "\t    self.target_df = pd.read_csv(target_path, **kwargs).rename(columns={match_fields['address'] : self.match_fields['address'], match_fields['zip'] : self.match_fields['zip']}).dropna(subset=[self.match_fields['address']]).set_index(self.match_fields['t_id'], drop=False).drop_duplicates(self.match_fields['t_id'])\n",
      "\n",
      "\t    self.target_df[self.match_fields['address']] = self.target_df[self.match_fields['address']].str.upper().str.replace('.', '').str.replace(',', '')\n",
      "\n",
      "            self.matched = pd.DataFrame(columns=self.match_fields.values())\n",
      "            self.unmatched = pd.DataFrame(columns=[self.match_fields['t_id'], self.match_fields['address'], self.match_fields['zip']])\n",
      "\n",
      "    def wf_split(self):\n",
      "\n",
      "            self.matched['FLAGS'] = ''\n",
      "\n",
      "\t    target_wf = self.target_df[self.match_fields['address']].str.extract('(\\d*) *(N|W|E|S|NORTH|WEST|EAST|SOUTH) *(%s) *(%s)' % (self.streetsort_str, self.abbrv_str)).dropna()\n",
      "\n",
      "\t    target_wf_addr = target_wf[0] + ' ' + target_wf[1] + ' ' + target_wf[2] + target_wf[3]\n",
      "\n",
      "\t    self.target_wf = pd.DataFrame(target_wf_addr, columns=[self.match_fields['address']])\n",
      "\t    self.target_wf[self.match_fields['t_id']] = self.target_wf.index\n",
      "\t    self.target_wf = pd.concat([self.target_wf, self.target_df[self.match_fields['zip']]], axis=1, join='inner')\n",
      "\n",
      "\t    self.target_nwf = self.target_df.loc[~self.target_df.index.isin(self.target_wf.index)]\n",
      "            self.target_nwf = self.target_nwf.loc[~(self.target_nwf[self.match_fields['address']].str.split().apply(lambda x: len(x)) == 1)]    #GEN\n",
      "\t    self.target_nwf[self.match_fields['address']] = self.target_nwf[self.match_fields['address']].str.replace(' {1,}', ' ')\n",
      "#\t    self.target_nwf['FID'] = self.target_nwf.index\n",
      "\n",
      "            self.unmatched = self.unmatched.append(self.target_wf).append(self.target_nwf)\n",
      "\n",
      "    def wf_parse(self):\n",
      "            \n",
      "            #### FIRST PASS--EXTRANEOUS INFORMATION (APT, BLDG, etc.)\n",
      "\n",
      "            firstpass = pd.merge(self.target_wf, self.match_wf, on=self.match_fields['address'], how='inner', suffixes=['_TARGET', '_MATCH']).drop_duplicates(subset=[self.match_fields['t_id']])\n",
      "\n",
      "            firstpass['FLAGS'] = 'ndst'\n",
      "            self.matched = pd.concat([self.matched, firstpass], axis=0)\n",
      "            self.unmatched = self.unmatched.drop(firstpass[self.match_fields['t_id']].unique())\n",
      "\n",
      "            comp_firstpass = self.target_wf.loc[~self.target_wf.index.isin(firstpass[self.match_fields['t_id']])]\n",
      "\n",
      "            comp_firstpass['SNUM'] = comp_firstpass[self.match_fields['address']].str.extract('(\\d*) *(N|W|E|S|NORTH|WEST|EAST|SOUTH) *(%s) *(%s)' % (self.streetsort_str, self.abbrv_str))[0]\n",
      "\n",
      "            comp_firstpass['DIR'] = comp_firstpass[self.match_fields['address']].str.extract('(\\d*) *(N|W|E|S|NORTH|WEST|EAST|SOUTH) *(%s) *(%s)' % (self.streetsort_str, self.abbrv_str))[1].str.replace('NORTH','N').str.replace('SOUTH','S').str.replace('WEST','W').str.replace('EAST','E') \n",
      "\n",
      "            comp_firstpass['STREET'] = comp_firstpass[self.match_fields['address']].str.extract('(\\d*) *(N|W|E|S|NORTH|WEST|EAST|SOUTH) *(%s) *(%s)' % (self.streetsort_str, self.abbrv_str))[2]\n",
      "\n",
      "            comp_firstpass['STYPE'] = comp_firstpass[self.match_fields['address']].str.extract('(\\d*) *(N|W|E|S|NORTH|WEST|EAST|SOUTH) *(%s) *(%s)' % (self.streetsort_str, self.abbrv_str))[3].str.replace(' ', '')\n",
      "\n",
      "            comp_firstpass['STYPE'] = comp_firstpass['STYPE'].map(pd.Series(self.abbrv.set_index(0)[1])).fillna(comp_firstpass['STYPE'])\n",
      "\n",
      "\n",
      "            #### SECOND PASS--DIFFERENT CARDINAL DIRECTION/STREET EXTENSION\n",
      "\n",
      "            secondpass = pd.merge(comp_firstpass, self.match_wf, on=['SNUM', 'DIR', 'STREET', 'STYPE'], how='inner', suffixes=['_TARGET', '_MATCH']).drop_duplicates(subset=[self.match_fields['t_id']])\n",
      "\n",
      "            self.matched = pd.concat([self.matched, secondpass], axis=0)            \n",
      "            self.unmatched = self.unmatched.drop(secondpass[self.match_fields['t_id']].unique())\n",
      "\n",
      "\n",
      "            comp_secondpass = comp_firstpass[~comp_firstpass.index.isin(secondpass[self.match_fields['t_id']])]\n",
      "\n",
      "            #### THIRD PASS--NON-MATCHING STREET NUMBER\n",
      "\n",
      "            test = pd.merge(comp_secondpass[comp_secondpass['SNUM'] != ''], self.match_wf[self.match_wf['SNUM'] != ''], on=['DIR', 'STREET', 'STYPE', self.match_fields['zip']], suffixes=['_TARGET', '_MATCH']).set_index(self.match_fields['t_id']).reset_index()\n",
      "\n",
      "            test['SNUM_DIFF'] = (test['SNUM_TARGET'].astype(int) - test['SNUM_MATCH'].astype(int))  \n",
      "\n",
      "            test['SNUM_ABS'] = (test['SNUM_TARGET'].astype(int) - test['SNUM_MATCH'].astype(int)).apply(lambda x: abs(x))\n",
      "\n",
      "            thirdpass = pd.DataFrame(columns=test.columns)\n",
      "\n",
      "            for i in test[self.match_fields['t_id']].unique():\n",
      "                t = test[test[self.match_fields['t_id']] == i]\n",
      "                ixmin_t = t['SNUM_ABS'].idxmin()\n",
      "                thirdpass = thirdpass.append(t.loc[ixmin_t])\n",
      "\n",
      "            self.thirdpass = thirdpass\n",
      "            thirdpass_matched = thirdpass.loc[thirdpass['SNUM_ABS'] < 100]\n",
      "\n",
      "            self.matched = pd.concat([self.matched, thirdpass_matched.drop_duplicates(self.match_fields['t_id'])], axis=0) #### NEEDS TO BE FIXED\n",
      "            self.unmatched = self.unmatched.drop(thirdpass_matched[self.match_fields['t_id']].unique())\n",
      "\n",
      "            comp_thirdpass = comp_secondpass[~comp_secondpass.index.isin(thirdpass[self.match_fields['t_id']].unique())]\n",
      "\n",
      "            #### FOURTH PASS--NON-MATCHING DIRECTION\n",
      "\n",
      "            fourthpass = pd.merge(comp_thirdpass[comp_thirdpass['SNUM'] != ''], self.match_wf[self.match_wf['SNUM'] != ''], on=['SNUM', 'STREET', 'STYPE', self.match_fields['zip']], suffixes=['_TARGET', '_MATCH'])\n",
      "\n",
      "            comp_fourthpass = comp_thirdpass[~comp_thirdpass.index.isin(fourthpass[self.match_fields['t_id']].unique())]\n",
      "\n",
      "            self.matched = pd.concat([self.matched, fourthpass], axis=0)\n",
      "            self.unmatched = self.unmatched.drop(fourthpass[self.match_fields['t_id']].unique())\n",
      "\n",
      "\n",
      "            #### FIFTH PASS--NON-MATCHING STREET TYPE\n",
      "\n",
      "            fifthpass = pd.merge(comp_fourthpass[comp_fourthpass['SNUM'] != ''], self.match_wf[self.match_wf['SNUM'] != ''], on=['SNUM', 'STREET', 'DIR', self.match_fields['zip']], suffixes=['_TARGET', '_MATCH'])\n",
      "\n",
      "            self.matched = pd.concat([self.matched, fifthpass], axis=0)\n",
      "            self.unmatched = self.unmatched.drop(fifthpass[self.match_fields['t_id']].unique())\n",
      "\n",
      "            \n",
      "            self.firstpass = firstpass\n",
      "            self.secondpass = secondpass\n",
      "            self.thirdpass = thirdpass\n",
      "            self.fourthpass = fourthpass\n",
      "            self.fifthpass = fifthpass\n",
      "            \n",
      "    def nwf_parse(self):\n",
      "        \n",
      "        nwf_1p = self.target_nwf[self.match_fields['address']].str.extract('^(\\d*) +(%s) *(%s)' % (self.streetsort_str, self.abbrv_str)).dropna().join(self.target_nwf[[self.match_fields['t_id'], self.match_fields['zip']]]).rename(columns={0:'SNUM', 1:'STREET', 2:'STYPE'})\n",
      "\n",
      "        nwf_1p['STYPE'] = nwf_1p['STYPE'].str.replace(' ', '').map(pd.Series(self.abbrv.set_index(0)[1])).fillna(nwf_1p['STYPE']).str.replace(' ', '')\n",
      "        \n",
      "        sixthpass = pd.merge(nwf_1p, self.match_wf, on=['SNUM', 'STREET', 'STYPE'], suffixes=['_TARGET', '_MATCH'])\n",
      "        self.matched = pd.concat([self.matched, sixthpass], axis=0)\n",
      "        self.unmatched = self.unmatched.drop(sixthpass[self.match_fields['t_id']].unique())\n",
      "\n",
      "\n",
      "        ######## MISSING/NONSTANDARD STREET TYPE \n",
      "        nwf_2p = self.target_nwf[self.match_fields['address']].str.extract('^(\\d*) *(W|N|E|S|WEST|NORTH|EAST|SOUTH) *(%s)$' % (self.streetsort_str)).dropna().join(self.target_nwf[[self.match_fields['t_id'], self.match_fields['zip']]]).rename(columns={0:'SNUM', 1:'DIR', 2:'STREET'})\n",
      "        \n",
      "        seventhpass = pd.merge(nwf_2p, self.match_wf, on=['SNUM', 'DIR', 'STREET'], suffixes=['_TARGET', '_MATCH'])\n",
      "        self.matched = pd.concat([self.matched, seventhpass], axis=0)\n",
      "        self.unmatched = self.unmatched.drop(seventhpass[self.match_fields['t_id']].unique())\n",
      "\n",
      "        ######## MISSING STREET TYPE AND APT\n",
      "\n",
      "        comp_nwf = self.target_nwf.drop(sixthpass[self.match_fields['t_id']].unique()).drop(seventhpass[self.match_fields['t_id']].unique())\n",
      "\n",
      "        nwf_3p = comp_nwf[self.match_fields['address']].str.extract('^(\\d*) *(W|N|E|S|WEST|NORTH|EAST|SOUTH) *(%s).*(APT|BLDG|#)' % (self.streetsort_str)).dropna().join(self.target_nwf[[self.match_fields['t_id'], self.match_fields['zip']]]).rename(columns={0: 'SNUM', 1:'DIR', 2:'STREET'})\n",
      "\n",
      "        eighthpass = pd.merge(nwf_3p, self.match_wf, on=['SNUM', 'DIR', 'STREET'], suffixes=['_TARGET', '_MATCH'])\n",
      "        self.matched = pd.concat([self.matched, eighthpass], axis=0)\n",
      "        self.unmatched = self.unmatched.drop(eighthpass[self.match_fields['t_id']].unique())\n",
      "\n",
      "\n",
      "        comp_nwf_2 = comp_nwf.drop(eighthpass[self.match_fields['t_id']].unique())\n",
      "\n",
      "        ####### MISSPELLINGS--PREP FUZZY MATCH\n",
      "        apts = pd.concat([comp_nwf_2, comp_nwf_2[self.match_fields['address']].str.extract('(.*) +(#|APT|BLDG)').dropna()[0]], axis=1, join='inner')\n",
      "        apts[self.match_fields['address']] = apts[0]\n",
      "        del apts[0]\n",
      "\n",
      "        nonapt = comp_nwf_2.drop(apts.index)\n",
      "\n",
      "        fuzzy_df = pd.concat([apts, nonapt], axis=0)\n",
      "\n",
      "        nwf_4p = fuzzy_df[self.match_fields['address']].str.extract(\"(\\d+) *(N\\.?|S\\.?|E\\.?|W\\.?) +([A-Z,0-9, ,-,',\\.]*) *( %s)$\" % (self.abbrv_str)).dropna()\n",
      "        nwf_4p.columns = ['SNUM', 'DIR', 'STREET', 'STYPE']\n",
      "\n",
      "        nwf_4p['STYPE'] = nwf_4p['STYPE'].str.replace(' ', '').map(pd.Series(self.abbrv.set_index(0)[1])).fillna(nwf_4p['STYPE']).str.replace(' ', '')\n",
      "\n",
      "        re_add = nwf_4p[nwf_4p.columns[0]].str.cat(others=[nwf_4p[i] for i in nwf_4p.columns[1:]], sep=' ')  \n",
      "\n",
      "        re_adzip = pd.concat([re_add, comp_nwf_2[self.match_fields['zip']]], axis=1, join='inner').rename(columns={'SNUM':self.match_fields['address']})\n",
      "\n",
      "        re_adzip[self.match_fields['t_id']] = re_adzip.index\n",
      "\n",
      "        fuzzy_matches = re_adzip.copy()\n",
      "        fuzzy_matches['MATCH_ADD'] = ''\n",
      "        fuzzy_matches[self.match_fields['id']] = ''\n",
      "        fuzzy_matches['MATCH_RATIO'] = 0.0\n",
      "\n",
      "        #u_stnm = pd.Series(street_names.unique())\n",
      "\n",
      "        for i in re_adzip.index:\n",
      "            srcadd = re_adzip.loc[i, self.match_fields['address']]\n",
      "            srczip = re_adzip.loc[i, self.match_fields['zip']]\n",
      "#            print srcadd, srczip\n",
      "            if srczip in self.match_wf[self.match_fields['zip']].unique():\n",
      "                src_df = self.match_wf[self.match_fields['address']].loc[self.match_wf[self.match_fields['zip']] == srczip]\n",
      "            else:\n",
      "                src_df = self.match_wf[self.match_fields['address']]\n",
      "            f_r = src_df.apply(lambda x: fuzz.ratio(srcadd, x)).max()\n",
      "            f_i = src_df.apply(lambda x: fuzz.ratio(srcadd, x)).idxmax()\n",
      "            fuzzy_matches.loc[i, 'MATCH_RATIO'] = f_r\n",
      "            fuzzy_matches.loc[i, 'MATCH_ADD'] = src_df.loc[f_i]\n",
      "            fuzzy_matches.loc[i, self.match_fields['id']] = self.match_wf.loc[f_i, self.match_fields['id']]\n",
      "#            print srcadd, f_r, f_i\n",
      "\n",
      "        ninthpass = fuzzy_matches.loc[fuzzy_matches['MATCH_RATIO'] >= 85]\n",
      "        ninthpass = pd.merge(ninthpass, self.match_df[[self.match_fields['id'], 'lat', 'lon']], on=self.match_fields['id'])\n",
      "\n",
      "\n",
      "        self.sixthpass = sixthpass\n",
      "        self.seventhpass = seventhpass\n",
      "        self.eighthpass = eighthpass\n",
      "        self.ninthpass = ninthpass\n",
      "\n",
      "        self.matched = pd.concat([self.matched, ninthpass], axis=0)\n",
      "        self.unmatched = self.unmatched.drop(ninthpass[self.match_fields['t_id']].unique())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#### CALL METHOD\n",
      "\n",
      "b = addr_match('/home/akagi/Desktop/assessor/mc_2014_full.csv', match_fields={'address':'SITE_ADDR', 'zip': 'S_ZIP', 'id': 'PARCEL_NUM', 'lat':'lat', 'lon':'lon'})\n",
      "b.abbrv_init('/home/akagi/Desktop/assessor/usps_abbrv.csv', header=None)\n",
      "b.prep_match()\n",
      "b.target_init('/home/akagi/Desktop/MCDPH_data/csv/DeathAddress.csv')\n",
      "b.wf_split()\n",
      "b.wf_parse()\n",
      "b.nwf_parse()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/pandas/io/parsers.py:1159: DtypeWarning: Columns (9,25,27,28,35,36) have mixed types. Specify dtype option on import or set low_memory=False.\n",
        "  data = self._reader.read(nrows)\n",
        "/usr/local/lib/python2.7/dist-packages/pandas/core/strings.py:189: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
        "  \" groups, use str.extract.\", UserWarning)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:110: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
        "-c:112: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:114: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
        "-c:116: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:118: SettingWithCopyWarning: \n",
        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
        "Try using .loc[row_indexer,col_indexer] = value instead\n",
        "\n",
        "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "known_addresses = b.target_df[b.target_df['SITE_ADDR'].str.split().str.len() != 1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print len(b.matched)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2547\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print float(len(b.matched))/len(known_addresses)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.675059634243\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Fuzzy matching"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "b.ninthpass[['SITE_ADDR', 'MATCH_ADD', 'MATCH_RATIO', 'lat', 'lon']].head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>SITE_ADDR</th>\n",
        "      <th>MATCH_ADD</th>\n",
        "      <th>MATCH_RATIO</th>\n",
        "      <th>lat</th>\n",
        "      <th>lon</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>      14813 N BOLIVARD DR</td>\n",
        "      <td>        14813  BOLIVAR DR</td>\n",
        "      <td> 94</td>\n",
        "      <td> 33.616640</td>\n",
        "      <td>-112.257350</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td> 2303 E HERMOSTA VISTA DR</td>\n",
        "      <td>  2303 E HERMOSA VISTA DR</td>\n",
        "      <td> 98</td>\n",
        "      <td> 33.458838</td>\n",
        "      <td>-111.781274</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2</th>\n",
        "      <td>   2507 E TIERRA BUENS LN</td>\n",
        "      <td>   2507 E TIERRA BUENA LN</td>\n",
        "      <td> 95</td>\n",
        "      <td> 33.629958</td>\n",
        "      <td>-112.028124</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>3</th>\n",
        "      <td>      4212 E AWHATUKEE DR</td>\n",
        "      <td>      4212 E AHWATUKEE DR</td>\n",
        "      <td> 95</td>\n",
        "      <td> 33.334501</td>\n",
        "      <td>-111.994223</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>4</th>\n",
        "      <td>            5002 S 22N PL</td>\n",
        "      <td>           5042 S 22ND PL</td>\n",
        "      <td> 89</td>\n",
        "      <td> 33.399943</td>\n",
        "      <td>-112.033583</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5</th>\n",
        "      <td>        3333 E TOPEKDA DR</td>\n",
        "      <td>         3333 E TOPEKA DR</td>\n",
        "      <td> 97</td>\n",
        "      <td> 33.660224</td>\n",
        "      <td>-112.009932</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>6</th>\n",
        "      <td>      16575 W ROOSEVEL ST</td>\n",
        "      <td>     16575 W ROOSEVELT ST</td>\n",
        "      <td> 97</td>\n",
        "      <td> 33.456687</td>\n",
        "      <td>-112.415329</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>7</th>\n",
        "      <td>           2228 N 55ND ST</td>\n",
        "      <td>           2228 N 52ND ST</td>\n",
        "      <td> 93</td>\n",
        "      <td> 33.472027</td>\n",
        "      <td>-111.970388</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>8</th>\n",
        "      <td> 18232 W PINNACLE PEAD RD</td>\n",
        "      <td> 18263 W PINNACLE PEAK RD</td>\n",
        "      <td> 92</td>\n",
        "      <td> 33.695770</td>\n",
        "      <td>-112.451489</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>9</th>\n",
        "      <td>         281 E MORALES ST</td>\n",
        "      <td>         281 E MORELOS ST</td>\n",
        "      <td> 88</td>\n",
        "      <td> 33.293657</td>\n",
        "      <td>-111.837513</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "                  SITE_ADDR                 MATCH_ADD  MATCH_RATIO        lat  \\\n",
        "0       14813 N BOLIVARD DR         14813  BOLIVAR DR           94  33.616640   \n",
        "1  2303 E HERMOSTA VISTA DR   2303 E HERMOSA VISTA DR           98  33.458838   \n",
        "2    2507 E TIERRA BUENS LN    2507 E TIERRA BUENA LN           95  33.629958   \n",
        "3       4212 E AWHATUKEE DR       4212 E AHWATUKEE DR           95  33.334501   \n",
        "4             5002 S 22N PL            5042 S 22ND PL           89  33.399943   \n",
        "5         3333 E TOPEKDA DR          3333 E TOPEKA DR           97  33.660224   \n",
        "6       16575 W ROOSEVEL ST      16575 W ROOSEVELT ST           97  33.456687   \n",
        "7            2228 N 55ND ST            2228 N 52ND ST           93  33.472027   \n",
        "8  18232 W PINNACLE PEAD RD  18263 W PINNACLE PEAK RD           92  33.695770   \n",
        "9          281 E MORALES ST          281 E MORELOS ST           88  33.293657   \n",
        "\n",
        "          lon  \n",
        "0 -112.257350  \n",
        "1 -111.781274  \n",
        "2 -112.028124  \n",
        "3 -111.994223  \n",
        "4 -112.033583  \n",
        "5 -112.009932  \n",
        "6 -112.415329  \n",
        "7 -111.970388  \n",
        "8 -112.451489  \n",
        "9 -111.837513  "
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "known_addresses = b.target_df[b.target_df['SITE_ADDR'].str.split().str.len() != 1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}